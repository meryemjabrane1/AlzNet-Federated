{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V5z3mYFsI3T"
      },
      "outputs": [],
      "source": [
        "#installing packages\n",
        "!pip install -q flwr[simulation] torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPgEwi-61v1d"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets\n",
        "import torchvision.models as models\n",
        "import os \n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader, random_split, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from PIL import Image\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#DEVICE = torch.device(\"cpu\")  # Try \"cuda\" to train on GPU\n",
        "#print(f\"Training on {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vKXfxB42T52"
      },
      "outputs": [],
      "source": [
        "CLASSES = (\n",
        "    \"MildDemented\",\n",
        "    \"ModerateDemented\",\n",
        "    \"NonDemented\",\n",
        "    \"VeryMildDemented\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSvHygkG3V-f"
      },
      "outputs": [],
      "source": [
        "NUM_CLIENTS = 3\n",
        "BATCH_SIZE = 64\n",
        "NBR_CLASSES = 4\n",
        "epochs = 5\n",
        "num_rounds=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wexj_PAnnbO"
      },
      "outputs": [],
      "source": [
        "# Defining Custom dataset class (still gotta know if its necessary or not)\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = os.listdir(self.root_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        img_path = os.path.join(self.root_dir, self.image_paths[idx])\n",
        "        image = Image.open(img_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JrzaxUFFq4C_"
      },
      "outputs": [],
      "source": [
        "\n",
        "!wget -O AugmentedAlzheimerDataset.zip https://dl.dropboxusercontent.com/s/g933yjln90vhrzk/AugmentedAlzheimerDataset.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aSLhl_frTMy"
      },
      "outputs": [],
      "source": [
        "!unzip AugmentedAlzheimerDataset.zip -d destination_folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0yy_ZBx8RpC"
      },
      "outputs": [],
      "source": [
        "def load_datasets():\n",
        "    import os\n",
        "\n",
        "    # Download and transform (train and test)\n",
        "    transform = transforms.Compose(\n",
        "            [transforms.ToTensor(),transforms.Resize((224,224)), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "        )\n",
        "\n",
        "    root_dir = \"/content/destination_folder/AugmentedAlzheimerDataset\"\n",
        "    print(\"Listing root directory contents:\")\n",
        "    print(os.listdir(root_dir))\n",
        "\n",
        "    for class_name in ['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented']:\n",
        "        class_dir = os.path.join(root_dir, class_name)\n",
        "        print(f\"Listing contents of {class_name} directory:\")\n",
        "        print(os.listdir(class_dir))\n",
        "\n",
        "    # Load Dataset\n",
        "    dataset = datasets.ImageFolder(root=root_dir, transform=transform)\n",
        "\n",
        "    # Define Training and Testing Sets\n",
        "    trainset_size=int(0.9*len(dataset))\n",
        "    testset_size= len(dataset)-trainset_size\n",
        "    train_dataset, test_dataset = random_split(dataset,[trainset_size,testset_size])\n",
        "\n",
        "    # Split training set into 3 partitions to simulate the individual dataset\n",
        "    partition_size = len(train_dataset) // NUM_CLIENTS\n",
        "    lengths = [partition_size] * NUM_CLIENTS\n",
        "    clientdatasets = random_split(train_dataset, lengths, torch.Generator().manual_seed(42))\n",
        "\n",
        "    # Split each partition into train/val and create DataLoader\n",
        "    trainloaders = []\n",
        "    valloaders = []\n",
        "    for ds in clientdatasets:\n",
        "        len_val = len(ds) // 10  # 10 % validation set\n",
        "        len_train = len(ds) - len_val\n",
        "        lengths = [len_train, len_val]\n",
        "        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))\n",
        "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
        "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
        "    testloader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    return trainloaders, valloaders, testloader\n",
        "\n",
        "trainloaders, valloaders, testloader = load_datasets()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yX30YdYr3Z3h"
      },
      "outputs": [],
      "source": [
        "images, labels = next(iter(trainloaders[0]))\n",
        "\n",
        "# Reshape and convert images to a NumPy array\n",
        "# matplotlib requires images with the shape (height, width, 3)\n",
        "images = images.permute(0, 2, 3, 1).numpy()\n",
        "# Denormalize\n",
        "images = images / 2 + 0.5\n",
        "\n",
        "# Create a figure and a grid of subplots\n",
        "fig, axs = plt.subplots(4, 8, figsize=(12, 6))\n",
        "\n",
        "# Loop over the images and plot them\n",
        "for i, ax in enumerate(axs.flat):\n",
        "    ax.imshow(images[i])\n",
        "    ax.set_title(CLASSES[labels[i]])\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "# Show the plot\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvCoZlfIfeBD"
      },
      "outputs": [],
      "source": [
        "#define model architecture\n",
        "model = models.densenet121(pretrained=True)\n",
        "#model = models.densenet121(progress=True)\n",
        "model.classifier = nn.Linear(1024, NBR_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6zktwXOzWdA"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(model, trainloader, epochs: int, parameters: List[np.ndarray] = None):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    model_parameters = [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
        "\n",
        "    if parameters is not None:\n",
        "        for param in parameters:\n",
        "            if param.size == 0:\n",
        "                print(\"Empty numpy array found!\")\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for images, labels in trainloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(model(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "def test(model, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlfVgmX03gjl"
      },
      "outputs": [],
      "source": [
        "trainloader = trainloaders[0]\n",
        "valloader = valloaders[0]\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train(model, trainloader, 1)\n",
        "    loss, accuracy = test(model, valloader)\n",
        "    print(f\"Epoch {epoch+1}: validation loss {loss}, accuracy {accuracy}\")\n",
        "\n",
        "loss, accuracy = test(model, testloader)\n",
        "print(f\"Final test set performance:\\n\\tloss {loss}\\n\\taccuracy {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfaVOpnuu7HZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, model, trainloader, valloader):\n",
        "        self.cid = cid\n",
        "        self.model = model\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "        train(self.model, self.trainloader, epochs=1)\n",
        "        return self.get_parameters(config), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "        loss, accuracy = test(self.model, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "def client_fn(cid) -> FlowerClient:\n",
        "    model_copy = models.densenet121(pretrained=True)\n",
        "    model_copy.classifier = nn.Linear(1024, NBR_CLASSES)\n",
        "    model_copy.to(device)\n",
        "    trainloader = trainloaders[int(cid)]\n",
        "    valloader = valloaders[int(cid)]\n",
        "    return FlowerClient(cid, model_copy, trainloader, valloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EiQFHk4_FFr"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq8Y9dMMmpIe"
      },
      "outputs": [],
      "source": [
        "# The `evaluate` function will be by Flower called after every round\n",
        "\n",
        "def evaluate(\n",
        "    server_round: int,\n",
        "    parameters: fl.common.NDArrays,\n",
        "    config: Dict[str, fl.common.Scalar],\n",
        "    model,\n",
        ") -> Optional[Tuple[float, Dict[str, fl.common.Scalar]]]:\n",
        "    print (f\"-------/{server_round}/--------{config}\")\n",
        "    model = model.to(device)\n",
        "    valloader = valloaders[0]\n",
        "\n",
        "    # Set model parameters directly without calling set_parameters function\n",
        "    for param in parameters:\n",
        "        if param.size == 0:\n",
        "            print(\"Empty numpy array found!\")\n",
        "\n",
        "    params_dict = zip(model.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    loss, accuracy = test(model, valloader)\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    torch.cuda.empty_cache()\n",
        "    return loss, {\"accuracy\": accuracy}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMQWBm5klGGD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def fit_config(server_round: int):\n",
        "    \"\"\"Return training configuration dict for each round.\n",
        "\n",
        "    Perform two rounds of training with one local epoch, increase to two local\n",
        "    epochs afterwards.\n",
        "    \"\"\"\n",
        "    config = {\n",
        "        \"server_round\": server_round,  # The current round of federated learning\n",
        "        \"local_epochs\": 1 if server_round < 2 else 2,  #\n",
        "    }\n",
        "    return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irXVPzOlFbZn",
        "outputId": "a91f4a10-5aeb-49cc-c4d9-b4999cc10dd7"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the model and get the parameters\n",
        "\n",
        "model_parameters = [val.cpu().numpy() for _, val in model.state_dict().items()]\n",
        "# Pass parameters to the Strategy for server-side parameter initialization\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,\n",
        "    fraction_evaluate=1.0,\n",
        "    min_fit_clients=2,\n",
        "    min_evaluate_clients=2,\n",
        "    min_available_clients=NUM_CLIENTS,\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(model_parameters),\n",
        "    on_fit_config_fn=fit_config  # Pass the fit_config function\n",
        "    # evaluate_fn=evaluate(server_round=0, parameters=model_parameters, config=fit_config(0), model=model),\n",
        ")\n",
        "\n",
        "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
        "client_resources = None\n",
        "if device.type == \"cuda\":\n",
        "    client_resources = {\"num_gpus\": 1}\n",
        "\n",
        "# Start simulation\n",
        "fl.simulation.start_simulation(\n",
        "    client_fn=client_fn,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=2),  # six rounds\n",
        "    strategy=strategy,\n",
        "    client_resources=client_resources,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuClass": "premium",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
